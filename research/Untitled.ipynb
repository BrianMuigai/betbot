{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = \"./Data/England/\"\n",
    "dataset1 = pd.read_csv(loc + 'training_dataset_model1.csv')\n",
    "dataset2 = pd.read_csv(loc + 'training_dataset_model2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' number of games to exclude in the training set for validation\n",
    "For example, if 240 games have been played, test_table has 250 fixtures - the last 10 being the ones that haven't\n",
    "been played. So, we set aside 20 fixtures from the training set(240 fixtures) for validation.''' \n",
    "num_games = dataset2.shape[0]-10\n",
    "v_split = 20\n",
    "n_games = num_games - v_split\n",
    "\n",
    "dataset2.drop(['pastHC','pastAS','pastAC','pastHG','pastAG'],axis=1)\n",
    "X_train2 = dataset2[['pastCornerDiff','pastGoalDiff','pastShotsDiff','HAS','HDS','AAS','ADS']].loc[0:n_games]\n",
    "y_train2 = dataset2['Result'].loc[0:n_games]\n",
    "X_test2 = dataset2[['pastCornerDiff','pastGoalDiff','pastShotsDiff','HAS','HDS','AAS','ADS']].loc[n_games:num_games-1]\n",
    "y_test2 = dataset2['Result'].loc[n_games:num_games-1]\n",
    "X_predict = dataset2[['pastCornerDiff','pastGoalDiff','pastShotsDiff','HAS','HDS','AAS','ADS']].loc[num_games:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = dataset1[['HAS','HDS','HST','AAS','ADS','AST','HC','AC','HTWS','HTDS','HTLS','ATWS','ATDS','ATLS',\n",
    "'HF','AF','CornerDiff','ShotsDiff','MW',]]\n",
    "y_all = dataset1['Result']\n",
    "\n",
    "X_train1 = X_all[:-140]\n",
    "X_test1 = X_all[-140:]\n",
    "y_train1 = y_all[:-140]\n",
    "y_test1 = y_all[-140:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, early_stopping=True, shuffle=False)\n",
    "clf\n",
    "param_grid={\n",
    "    'learning_rate':[0.05, 0.01, 0.005, 0.001],\n",
    "    'activation'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60157791 0.62919132 0.60474308 0.57905138 0.57312253 0.5513834\n",
      " 0.60671937 0.57905138 0.66403162 0.63366337]\n",
      "0.6022535363904283\n",
      "Training Accuracy:  0.6352499506026477\n",
      "Testing Accuracy:  0.6571428571428571\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.fit(X_train1,y_train1).predict(X_train1)\n",
    "accuracy1 = accuracy_score(y_pred,y_train1)\n",
    "accuracy2 = accuracy_score(clf.predict(X_test1),y_test1)\n",
    "scores = cross_val_score(clf, X_train1, y_train1, cv=10)\n",
    "print( scores)\n",
    "print (scores.mean())\n",
    "print('Training Accuracy: ', accuracy1)\n",
    "print('Testing Accuracy: ', accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42105263 0.52923977 0.52631579 0.46783626 0.49852507 0.51032448\n",
      " 0.48082596 0.47492625 0.46902655 0.44247788]\n",
      "0.482055063913471\n",
      "Training Accuracy:  0.5094062316284539\n",
      "Testing Accuracy:  0.6\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.fit(X_train2,y_train2).predict(X_train2)\n",
    "accuracy1 = accuracy_score(y_pred,y_train2)\n",
    "accuracy2 = accuracy_score(clf.predict(X_test2),y_test2)\n",
    "scores = cross_val_score(clf, X_train2, y_train2, cv=10)\n",
    "print( scores)\n",
    "print (scores.mean())\n",
    "print('Training Accuracy: ', accuracy1)\n",
    "print('Testing Accuracy: ', accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  0,  1,  1,  1, -1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_week = clf.fit(X_train2, y_train2).predict(X_predict)\n",
    "this_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
